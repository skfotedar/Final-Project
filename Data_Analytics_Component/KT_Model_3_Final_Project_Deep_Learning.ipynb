{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZNhGcW6q6r"
      },
      "source": [
        "# Final Project: Deep Neutral Network with KerasTuner\n",
        "## Model 3: Predict Glacier Retreat with Tensor Flow's Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Keras Tuner hyperparameters used here are:\n",
        "\n",
        "{'activation': 'relu', 'first_units': 21, 'num_layers': 4, 'units_0': 11, 'units_1': 6, 'units_2': 16, 'units_3': 11, 'units_4': 16, 'tuner/epochs': 20, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
        "\n",
        "The use of Keras Tuner provided the first pass response of Loss: 1.162386417388916, Accuracy: 0.6666666865348816\n",
        "The final model after several iterations was improved to Loss: 0.8554542064666748, Accuracy: 0.7777777910232544"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0otrXpJc6q6u"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpV4Y-3Z6q6w"
      },
      "source": [
        "---\n",
        "\n",
        "Step 1: Prepare the data to be used on a neural network model\n",
        "\n",
        "Note:  The raw data files have been cleaned and prepared for use in the\n",
        "\n",
        "Jupyter Source File \"Data_Cleaning_Glacier_Retreat\".  The output for this file\n",
        "\n",
        "is in the \"resources\" folder and includes data sets for each of the following:\n",
        "1.  Environmental Parameters:  Global Temperature, Global Sea Rise, and Global CO2\n",
        "        Filename:  env_parameters_1.csv\n",
        "\n",
        "2.  Population, Economic, and Farming Parameters: World Population, Urban Population,\n",
        "        investment, and cereal output production by acre.\n",
        "        filename: pop_farm_parameters_2.csv\n",
        "\n",
        "3.  Change in Temperature by Country:  Average delta T by country.\n",
        "        filename: dT_Country_parameters_3.csv\n",
        "\n",
        "4.  Change in Forestation by Country:  Percent change in forestation by country.\n",
        "        filename: deforest_parameters_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Third Model: Glacier Retreat with Change in Temperature by Country"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>glacier_retreat</th>\n",
              "      <th>AFG</th>\n",
              "      <th>ALB</th>\n",
              "      <th>DZA</th>\n",
              "      <th>AND</th>\n",
              "      <th>AGO</th>\n",
              "      <th>ARG</th>\n",
              "      <th>AUS</th>\n",
              "      <th>AUT</th>\n",
              "      <th>...</th>\n",
              "      <th>USA</th>\n",
              "      <th>VIR</th>\n",
              "      <th>URY</th>\n",
              "      <th>VUT</th>\n",
              "      <th>VEN</th>\n",
              "      <th>VNM</th>\n",
              "      <th>PSE</th>\n",
              "      <th>WLD</th>\n",
              "      <th>ZMB</th>\n",
              "      <th>ZWE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1979</td>\n",
              "      <td>0</td>\n",
              "      <td>0.361</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.654</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0.375</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.306</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.416</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.226</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1980</td>\n",
              "      <td>1</td>\n",
              "      <td>0.600</td>\n",
              "      <td>-0.414</td>\n",
              "      <td>0.232</td>\n",
              "      <td>-0.188</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.373</td>\n",
              "      <td>0.887</td>\n",
              "      <td>-0.274</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.147</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.368</td>\n",
              "      <td>-0.204</td>\n",
              "      <td>0.332</td>\n",
              "      <td>0.138</td>\n",
              "      <td>-0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1981</td>\n",
              "      <td>0</td>\n",
              "      <td>0.483</td>\n",
              "      <td>-0.351</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.178</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.277</td>\n",
              "      <td>...</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.490</td>\n",
              "      <td>-0.215</td>\n",
              "      <td>0.443</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>-0.360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1982</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.346</td>\n",
              "      <td>0.173</td>\n",
              "      <td>0.399</td>\n",
              "      <td>1.044</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.359</td>\n",
              "      <td>0.186</td>\n",
              "      <td>0.384</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>0.052</td>\n",
              "      <td>0.574</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.196</td>\n",
              "      <td>-0.562</td>\n",
              "      <td>0.086</td>\n",
              "      <td>0.340</td>\n",
              "      <td>0.170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1983</td>\n",
              "      <td>1</td>\n",
              "      <td>0.164</td>\n",
              "      <td>-0.128</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.859</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.633</td>\n",
              "      <td>1.062</td>\n",
              "      <td>...</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.552</td>\n",
              "      <td>-0.052</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.469</td>\n",
              "      <td>0.082</td>\n",
              "      <td>-1.068</td>\n",
              "      <td>0.460</td>\n",
              "      <td>1.064</td>\n",
              "      <td>1.223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  glacier_retreat    AFG    ALB    DZA    AND    AGO    ARG    AUS  \\\n",
              "0  1979                0  0.361  0.203  0.654  0.058  0.291  0.266  0.375   \n",
              "1  1980                1  0.600 -0.414  0.232 -0.188  0.279  0.373  0.887   \n",
              "2  1981                0  0.483 -0.351  0.215  0.178 -0.071  0.378  0.495   \n",
              "3  1982                1 -0.346  0.173  0.399  1.044  0.164  0.359  0.186   \n",
              "4  1983                1  0.164 -0.128  0.560  0.859  0.487  0.046  0.633   \n",
              "\n",
              "     AUT  ...    USA    VIR    URY    VUT    VEN    VNM    PSE    WLD    ZMB  \\\n",
              "0 -0.112  ... -0.306 -0.062  0.128  0.103  0.202  0.416  0.606  0.226  0.249   \n",
              "1 -0.274  ...  0.412  0.718  0.571  0.147  0.346  0.368 -0.204  0.332  0.138   \n",
              "2  0.277  ...  0.871  0.514  0.500  0.099  0.134  0.490 -0.215  0.443 -0.158   \n",
              "3  0.384  ... -0.343  0.052  0.574  0.072  0.116  0.196 -0.562  0.086  0.340   \n",
              "4  1.062  ...  0.540  0.552 -0.052  0.215  0.469  0.082 -1.068  0.460  1.064   \n",
              "\n",
              "     ZWE  \n",
              "0  0.189  \n",
              "1 -0.024  \n",
              "2 -0.360  \n",
              "3  0.170  \n",
              "4  1.223  \n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Review and load the dataset for Typical Climate Change Measurements\n",
        "file_path = \"resources\\dT_Country_parameters_3.csv\"\n",
        "df_parameters_1 = pd.read_csv(file_path)\n",
        "\n",
        "# Review the DataFrame\n",
        "df_parameters_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9P8aX-dW75JO",
        "outputId": "eb66ceff-c400-4935-b1f8-a692d4489ec2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "glacier_retreat\n",
              "0    25\n",
              "1    19\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the glacier retreat value counts\n",
        "df_parameters_1[\"glacier_retreat\"].value_counts()\n",
        "# low quantity but evenly split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6vbZeDH6q6y"
      },
      "source": [
        "Step 2: Using the preprocessed data, create the features (`X`) and target (`y`) datasets. The target dataset should be defined by the preprocessed DataFrame column “glacier_retreat”. The remaining columns should define the features dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5eVAP5M6q6y",
        "outputId": "1c30e844-11ca-4c0b-bd94-a943b9d3f558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
              "      dtype=int64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the target set y using the glacier_retreat column\n",
        "# Remember that .values creates a numpy array\n",
        "y = df_parameters_1[\"glacier_retreat\"].values\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IIkrD2Sn6q6z",
        "outputId": "d611ed8c-6987-4e51-a350-af6f4f79d734"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AFG</th>\n",
              "      <th>ALB</th>\n",
              "      <th>DZA</th>\n",
              "      <th>AND</th>\n",
              "      <th>AGO</th>\n",
              "      <th>ARG</th>\n",
              "      <th>AUS</th>\n",
              "      <th>AUT</th>\n",
              "      <th>BHS</th>\n",
              "      <th>BHR</th>\n",
              "      <th>...</th>\n",
              "      <th>USA</th>\n",
              "      <th>VIR</th>\n",
              "      <th>URY</th>\n",
              "      <th>VUT</th>\n",
              "      <th>VEN</th>\n",
              "      <th>VNM</th>\n",
              "      <th>PSE</th>\n",
              "      <th>WLD</th>\n",
              "      <th>ZMB</th>\n",
              "      <th>ZWE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.361</td>\n",
              "      <td>0.203</td>\n",
              "      <td>0.654</td>\n",
              "      <td>0.058</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0.375</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>0.133</td>\n",
              "      <td>0.856</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.306</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>0.128</td>\n",
              "      <td>0.103</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.416</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.226</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.600</td>\n",
              "      <td>-0.414</td>\n",
              "      <td>0.232</td>\n",
              "      <td>-0.188</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.373</td>\n",
              "      <td>0.887</td>\n",
              "      <td>-0.274</td>\n",
              "      <td>0.377</td>\n",
              "      <td>0.351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.718</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.147</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.368</td>\n",
              "      <td>-0.204</td>\n",
              "      <td>0.332</td>\n",
              "      <td>0.138</td>\n",
              "      <td>-0.024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.483</td>\n",
              "      <td>-0.351</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.178</td>\n",
              "      <td>-0.071</td>\n",
              "      <td>0.378</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.277</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>0.408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.099</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.490</td>\n",
              "      <td>-0.215</td>\n",
              "      <td>0.443</td>\n",
              "      <td>-0.158</td>\n",
              "      <td>-0.360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     AFG    ALB    DZA    AND    AGO    ARG    AUS    AUT    BHS    BHR  ...  \\\n",
              "0  0.361  0.203  0.654  0.058  0.291  0.266  0.375 -0.112  0.133  0.856  ...   \n",
              "1  0.600 -0.414  0.232 -0.188  0.279  0.373  0.887 -0.274  0.377  0.351  ...   \n",
              "2  0.483 -0.351  0.215  0.178 -0.071  0.378  0.495  0.277 -0.030  0.408  ...   \n",
              "\n",
              "     USA    VIR    URY    VUT    VEN    VNM    PSE    WLD    ZMB    ZWE  \n",
              "0 -0.306 -0.062  0.128  0.103  0.202  0.416  0.606  0.226  0.249  0.189  \n",
              "1  0.412  0.718  0.571  0.147  0.346  0.368 -0.204  0.332  0.138 -0.024  \n",
              "2  0.871  0.514  0.500  0.099  0.134  0.490 -0.215  0.443 -0.158 -0.360  \n",
              "\n",
              "[3 rows x 150 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AFG</th>\n",
              "      <th>ALB</th>\n",
              "      <th>DZA</th>\n",
              "      <th>AND</th>\n",
              "      <th>AGO</th>\n",
              "      <th>ARG</th>\n",
              "      <th>AUS</th>\n",
              "      <th>AUT</th>\n",
              "      <th>BHS</th>\n",
              "      <th>BHR</th>\n",
              "      <th>...</th>\n",
              "      <th>USA</th>\n",
              "      <th>VIR</th>\n",
              "      <th>URY</th>\n",
              "      <th>VUT</th>\n",
              "      <th>VEN</th>\n",
              "      <th>VNM</th>\n",
              "      <th>PSE</th>\n",
              "      <th>WLD</th>\n",
              "      <th>ZMB</th>\n",
              "      <th>ZWE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.498</td>\n",
              "      <td>1.498</td>\n",
              "      <td>1.926</td>\n",
              "      <td>2.562</td>\n",
              "      <td>1.162</td>\n",
              "      <td>1.123</td>\n",
              "      <td>1.416</td>\n",
              "      <td>2.315</td>\n",
              "      <td>1.611</td>\n",
              "      <td>2.027</td>\n",
              "      <td>...</td>\n",
              "      <td>1.324</td>\n",
              "      <td>1.320</td>\n",
              "      <td>0.890</td>\n",
              "      <td>1.226</td>\n",
              "      <td>1.350</td>\n",
              "      <td>1.477</td>\n",
              "      <td>1.455</td>\n",
              "      <td>1.711</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1.327</td>\n",
              "      <td>1.536</td>\n",
              "      <td>2.330</td>\n",
              "      <td>1.533</td>\n",
              "      <td>1.553</td>\n",
              "      <td>1.031</td>\n",
              "      <td>0.629</td>\n",
              "      <td>1.395</td>\n",
              "      <td>0.879</td>\n",
              "      <td>2.464</td>\n",
              "      <td>...</td>\n",
              "      <td>1.144</td>\n",
              "      <td>0.922</td>\n",
              "      <td>0.790</td>\n",
              "      <td>1.147</td>\n",
              "      <td>0.734</td>\n",
              "      <td>1.114</td>\n",
              "      <td>1.787</td>\n",
              "      <td>1.447</td>\n",
              "      <td>0.822</td>\n",
              "      <td>-0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2.012</td>\n",
              "      <td>1.518</td>\n",
              "      <td>1.688</td>\n",
              "      <td>3.243</td>\n",
              "      <td>1.212</td>\n",
              "      <td>0.643</td>\n",
              "      <td>0.754</td>\n",
              "      <td>2.498</td>\n",
              "      <td>1.480</td>\n",
              "      <td>2.017</td>\n",
              "      <td>...</td>\n",
              "      <td>1.217</td>\n",
              "      <td>0.894</td>\n",
              "      <td>0.382</td>\n",
              "      <td>1.479</td>\n",
              "      <td>0.533</td>\n",
              "      <td>1.033</td>\n",
              "      <td>1.074</td>\n",
              "      <td>1.394</td>\n",
              "      <td>0.686</td>\n",
              "      <td>-0.490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      AFG    ALB    DZA    AND    AGO    ARG    AUS    AUT    BHS    BHR  ...  \\\n",
              "41  0.498  1.498  1.926  2.562  1.162  1.123  1.416  2.315  1.611  2.027  ...   \n",
              "42  1.327  1.536  2.330  1.533  1.553  1.031  0.629  1.395  0.879  2.464  ...   \n",
              "43  2.012  1.518  1.688  3.243  1.212  0.643  0.754  2.498  1.480  2.017  ...   \n",
              "\n",
              "      USA    VIR    URY    VUT    VEN    VNM    PSE    WLD    ZMB    ZWE  \n",
              "41  1.324  1.320  0.890  1.226  1.350  1.477  1.455  1.711  0.891  0.389  \n",
              "42  1.144  0.922  0.790  1.147  0.734  1.114  1.787  1.447  0.822 -0.125  \n",
              "43  1.217  0.894  0.382  1.479  0.533  1.033  1.074  1.394  0.686 -0.490  \n",
              "\n",
              "[3 rows x 150 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Define features set X by selecting remaining columns, drop year and \n",
        "# glacier_retreat\n",
        "X = df_parameters_1.drop([\"year\",\"glacier_retreat\"],axis=1)\n",
        "\n",
        "# Review the features DataFrame\n",
        "display(X.head(3),X.tail(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmM9c-tj6q6z"
      },
      "source": [
        "### Step 3: Split the features and target sets into training and testing datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OD7xwU_96q6z"
      },
      "outputs": [],
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "# Assign the function a random_state equal to 13\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9i6DHY06q6z"
      },
      "source": [
        "### Step 4: Use scikit-learn's `StandardScaler` to scale the features data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BzD3z20m6q6z"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features training dataset\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the Data <<< added by student\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZzVDjba6q6z"
      },
      "source": [
        "---\n",
        "\n",
        "## Compile and Evaluate a Model Using a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-pSux4Q6q60"
      },
      "source": [
        "### Step 1: Create a deep neural network by assigning the number of input features, the number of layers, and the number of neurons on each layer using Tensorflow’s Keras.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5C94FCd6q60",
        "outputId": "0d3a0d11-91cf-468c-fdc2-c82c95bf4d56"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the the number of inputs (features) to the model\n",
        "number_input_features = len(X_train.columns)\n",
        "# Review the number of features\n",
        "number_input_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c_KXDLkF6q60"
      },
      "outputs": [],
      "source": [
        "#Note: KerasTuner Values\n",
        "\n",
        "# Define the number of hidden nodes in each layer\n",
        "hidden_nodes_layer1 = 11\n",
        "hidden_nodes_layer2 = 6\n",
        "hidden_nodes_layer3 = 16\n",
        "hidden_nodes_layer4 = 11\n",
        "\n",
        "# Define the number of neurons in the output layer\n",
        "nn_output_layer = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63UdFncw6q60",
        "outputId": "4375e0d1-3794-4224-8f77-7c3557fb0c3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\frisb\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Create the Sequential model instance\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Add Hidden Layers\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,\n",
        "                             input_dim=number_input_features,activation=\"relu\"))\n",
        "\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
        "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
        "\n",
        "# Add the output layer to the model specifying the number of output neurons\n",
        "# and activation function\n",
        "nn.add(tf.keras.layers.Dense(units=nn_output_layer, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "-Beoh4f_6q61",
        "outputId": "1b9b9749-b9aa-4603-aa8a-0db3014ddd9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,661</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │         \u001b[38;5;34m1,661\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m72\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m187\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,044</span> (7.98 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,044\u001b[0m (7.98 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the Sequential model summary\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRqWGIRo6q61"
      },
      "source": [
        "### Step 2: Compile and fit the model using the `binary_crossentropy` loss function, the `adam` optimizer, and the `accuracy` evaluation metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E-hZaeSn6q61"
      },
      "outputs": [],
      "source": [
        "# Compile the Sequential model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x25e8Idc6q61",
        "outputId": "23444df1-fa0f-40b9-961d-ee066a3fd001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5348 - loss: 0.6898\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5348 - loss: 0.6786 \n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 0.6705 \n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 0.6635 \n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.6566 \n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.6457 \n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5719 - loss: 0.6412 \n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6623 - loss: 0.6293 \n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5998 - loss: 0.6456 \n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6415 - loss: 0.6276 \n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6519 - loss: 0.6176 \n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.6311 - loss: 0.6172  \n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6311 - loss: 0.6181 \n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6623 - loss: 0.6036 \n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 0.5931 \n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6474 - loss: 0.6051 \n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.5898 \n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.7320 - loss: 0.5836 \n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7645 - loss: 0.5870 \n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.7378 - loss: 0.5744  \n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.7274 - loss: 0.5716  \n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.7807 - loss: 0.5634  \n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7866 - loss: 0.5715\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.5631 \n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.5405 \n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.5364 \n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.5259 \n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.5234 \n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.5367 \n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.5234 \n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.5154 \n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8666 - loss: 0.5033 \n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 0.4937 \n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.4846 \n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.4761 \n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.4639 \n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.4573 \n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.4557 \n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.9141 - loss: 0.4401\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9200 - loss: 0.4391  \n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9408 - loss: 0.4080  \n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9408 - loss: 0.4097  \n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9304 - loss: 0.4084  \n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9304 - loss: 0.3844  \n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.3782  \n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.3798  \n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9466 - loss: 0.3776\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.3672  \n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.3500  \n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.3547  \n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9200 - loss: 0.3468  \n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9304 - loss: 0.3347 \n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.3351  \n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.3011  \n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.3045  \n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.3029  \n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9675 - loss: 0.2765  \n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.2841  \n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.2772  \n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9466 - loss: 0.2648  \n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9571 - loss: 0.2589  \n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.2553 \n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9733 - loss: 0.2344  \n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.2346\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.2228 \n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9733 - loss: 0.2175  \n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9733 - loss: 0.2026\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9733 - loss: 0.1976  \n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9733 - loss: 0.1900  \n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9733 - loss: 0.1954  \n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9733 - loss: 0.1747\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1720  \n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1577  \n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1511  \n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1570  \n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.1468 \n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1415  \n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1375  \n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1241\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1249  \n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1235  \n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1160  \n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1138  \n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1105  \n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.1038  \n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0988\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0980 \n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0958  \n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0885  \n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0779  \n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0816  \n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0783  \n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0813  \n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0769  \n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0733  \n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0704 \n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0723  \n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 1.0000 - loss: 0.0707  \n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0635 \n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0677 \n"
          ]
        }
      ],
      "source": [
        "# Fit the model using 20 epochs and the training data\n",
        "\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfHMPZVI6q61"
      },
      "source": [
        "Step 3: Evaluate the model using the test data to determine the model’s loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hfVADKo6q61",
        "outputId": "16a8fc63-2914-4c3f-ac25-0310315270f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 0s - 108ms/step - accuracy: 0.6667 - loss: 1.1624\n",
            "Loss: 1.162386417388916, Accuracy: 0.6666666865348816\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "\n",
        "# Display the model loss and accuracy results\n",
        "# Note:  \n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note:  This model does not provide much assistance in predicting outcome.\n",
        "\n",
        "Future work:  The glacier retreat response could be slow to respond.  Try\n",
        "shifting the data.\n",
        "\n",
        "Future work:  Vary the X data, removing some columns and leaving others\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpAv0rXA6q61"
      },
      "source": [
        "Step 4: Save and export the model to file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "q0MetN0W6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path('saved_models/kt_model_3.keras')\n",
        "\n",
        "# Export your model to a keras file\n",
        "nn.save(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1opCDdN6q61"
      },
      "source": [
        "---\n",
        "### Predict Glacier Retreat by Using your Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfIfpeiy6q61"
      },
      "source": [
        "Step 1: Reload the saved model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OCET2mvW6q61"
      },
      "outputs": [],
      "source": [
        "# Set the model's file path\n",
        "file_path = Path('saved_models/kt_model_3.keras')\n",
        "\n",
        "# Load the model to a new object\n",
        "nn = tf.keras.models.load_model(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTPKooGw6q61"
      },
      "source": [
        "Step 2: Make predictions on the testing data and save the predictions to a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vet7qjgx6q62",
        "outputId": "55bfea7f-40b4-4e59-cab9-fc882ea5cd45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 - 0s - 44ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[4.5044910e-02],\n",
              "       [2.5747294e-04],\n",
              "       [3.2077745e-01]], dtype=float32)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions with the test data\n",
        "predictions = nn.predict(X_test_scaled,verbose=2)\n",
        "\n",
        "# Display a sample of the predictions\n",
        "predictions[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "87o8exFPhjfl",
        "outputId": "83e96149-19db-449c-df68-54cdc6152fb8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predictions\n",
              "0          0.0\n",
              "1          0.0\n",
              "2          0.0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the predictions to a DataFrame and round the predictions to binary results\n",
        "predictions_df = pd.DataFrame(columns=[\"predictions\"], data=predictions)\n",
        "predictions_df[\"predictions\"] = round(predictions_df[\"predictions\"],0)\n",
        "predictions_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxxLwycg6q62"
      },
      "source": [
        "### Step 4: Display a classification report with the y test data and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTxYZibW6q67",
        "outputId": "00b45c02-3424-4a19-e441-41ecebe6d0a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\frisb\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\frisb\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\frisb\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Print the classification report with the y test data and predictions\n",
        "print(classification_report(y_test, predictions_df[\"predictions\"].values))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
